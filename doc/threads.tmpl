            +----------------------+
            |        OS 211        |
            |  TASK 1: SCHEDULING  |
            |    DESIGN DOCUMENT   |
            +----------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, or notes for the
>> markers, please give them here.

>> Please cite any offline or online sources you consulted while preparing your 
>> submission, other than the PintOS documentation, course text, lecture notes 
>> and course staff.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> A1: (2 marks) 
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration.  
>> Identify the purpose of each in roughly 25 words.

>> A2: (4 marks) 
>> Draw a diagram that illustrates a nested donation in your structure and 
>> briefly explain how this works.

---- ALGORITHMS ----

>> A3: (3 marks) 
>> How do you ensure that the highest priority waiting thread wakes up first for
>> a (i) semaphore, (ii) lock, or (iii) condition variable?

(i) When sema_down() is called, the thread with highest priority in waiters would 
always be unblocked first, and the current thread would yield if it has lower 
priority.
(ii) As a lock contains a semaphore, modifying the semaphore would suffice.
(iii) An extra field priority storing current thread's priority is added to 
semaphore_elem, so that sema_up() could be called according to priority in 
cond_signal().

>> A4: (3 marks)
>> Describe the sequence of events when a call to lock_acquire() causes a 
>> priority donation. 
>> How is nested donation handled?

When lock_acquire() is called, if the BSD scheduler is not in use and the lock holder 
is not null, then the recursive priority donation process starts. For current thread, we 
check that if it is trying to acquire a lock. If the lock's priority is lower then the 
thread's priority, priority donation is needed. The priorities of both the lock and its 
holder need to be updated. The current thread is then set to be the lock holder. The 
process repeats until the checks failed.

>> A5: (3 marks)
>> Describe the sequence of events when lock_release() is called on a lock that 
>> a higher-priority thread is waiting for.

When lock_release() is called, the lock is removed from the lock list, the thread's 
effective priority is being updated. sema_up() is then called. Within sema_up(), the 
lock's priority is being updated. If a higher-priority thread is waiting, then the 
current thread would yield after the waiting thread being unblocked.

---- SYNCHRONIZATION ----

>> A6: (2 marks)
>> How do you avoid a race condition in thread_set_priority() when a thread 
>> needs to recompute its effective priority, but the donated priorities 
>> potentially change during the computation?
>> Can you use a lock to avoid the race?

---- RATIONALE ----

>> A7: (3 marks)
>> Why did you choose this design?  
>> In what ways is it superior to another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> B1: (2 marks)
>> Copy here the declaration of each new or changed `struct' or `struct' member,
>> global or static variable, `typedef', or enumeration. 
>> Identify the purpose of each in roughly 25 words.

>> Changed `struct` member:
struct thread 
{
    int nice;                           /* nice value, -20 <= nice <= 20 */
    fp recent_cpu;                      /* The amount of CPU time a thread has received “recently” */
}
- nice will alter the value of priority, initial thread nice = 0, others inherit parent nice
- recent_cpu measures how much CPU time each process has received "recently"
  recalculates once per second
  initial thread = 0, others inherit form parent recent_cpu
  recent_cpu++ for the running thread during each timer interrupt

>> New static variable:
static fp load_avg;  /* Estimates the average number of threads ready to run over the past minute */
 - load_avg is system-wide, not thread-specific, hence not belongs to struct thread
 - estimates the average number of threads ready to run over the past minute

---- ALGORITHMS ----

>> B2: (3 marks)
>> Suppose threads A, B, and C have nice values 0, 1, and 2 and each has a 
>> recent_cpu value of 0. 
>> Fill in the table below showing the scheduling decision, the priority and the
>> recent_cpu values for each thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0   
 4
 8
12
16
20
24
28
32
36

>> B3: (2 marks) 
>> Did any ambiguities in the scheduler specification make values in the table 
>> uncertain? 
>> If so, what rule did you use to resolve them?

---- RATIONALE ----

>> B4: (3 marks)
>> Briefly critique your design, pointing out advantages and disadvantages in 
>> your design choices.

>> Design:
- Simplicity and clarity.
- Most algorithms are organised into different functions, that are built on top of the given helper functions
- Macro for fixed-point calculations


>> Advantages:
- Use of macro, which is faster
- Use of thread_foreach(thread_action_func *action, void *aux), in particular calculates the load_avg and pass this into
  the thread_foreach function to prevent duplicates calculations inside the action function for each thread
- Clarity

>> Disadvantages:
- Didn't use a 64 queues, used one single queue instead
- Could results in a lower efficiency when the queue becomes very large
